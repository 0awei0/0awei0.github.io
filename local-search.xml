<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>搜索引擎-倒排索引</title>
    <link href="/2022/10/14/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E-%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/"/>
    <url>/2022/10/14/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E-%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>从零开始做一个搜索引擎--PageRank值计算</title>
    <link href="/2022/10/14/PageRank%E5%80%BC%E8%AE%A1%E7%AE%97/"/>
    <url>/2022/10/14/PageRank%E5%80%BC%E8%AE%A1%E7%AE%97/</url>
    
    <content type="html"><![CDATA[<h1 id="搜索引擎–PageRank值计算"><a href="#搜索引擎–PageRank值计算" class="headerlink" title="搜索引擎–PageRank值计算"></a>搜索引擎–<code>PageRank</code>值计算</h1><h2 id="1-什么是PageRank"><a href="#1-什么是PageRank" class="headerlink" title="1.什么是PageRank"></a>1.什么是<code>PageRank</code></h2><p><code>PageRank</code>，又称网页排名、谷歌左侧排名，是一种由搜索引擎根据网页之间相互的超链接计算的技术，而作为网页排名的要素之一，以Google公司创办人拉里·佩奇（Larry Page）之姓来命名。Google用它来体现网页的相关性和重要性，在搜索引擎优化操作中是经常被用来评估网页优化的成效因素之一。</p><p>这里就不讲具体的原理了，我们直接来看一个例子，怎么用<code>networkx</code>库来计算图中每个节点的<code>PageRank</code>值。</p><h2 id="2-PageRank值计算"><a href="#2-PageRank值计算" class="headerlink" title="2.PageRank值计算"></a>2.<code>PageRank</code>值计算</h2><h3 id="2-1-下载networkx库"><a href="#2-1-下载networkx库" class="headerlink" title="2.1 下载networkx库"></a>2.1 下载<code>networkx</code>库</h3><p>直接在命令行输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">pip install networkx<br></code></pre></td></tr></table></figure><p>可能会安装失败，如果安装失败就去网上搜教程，如果安装成功并且可以使用，那就当我没说。</p><h3 id="2-2使用networkx计算PageRank值"><a href="#2-2使用networkx计算PageRank值" class="headerlink" title="2.2使用networkx计算PageRank值"></a>2.2使用<code>networkx</code>计算<code>PageRank</code>值</h3><p>假设我们现在有这样一个图</p><p><img src="%E4%B8%8B%E8%BD%BD.png" alt="下载"></p><p>我们怎么用<code>networkx</code>计算图中每个节点的<code>PageRank</code>值呢。<code>networkx</code>中提供了一个方法，可以很简单的计算出<code>PageRank</code>值，只要我们把图中所有边都加入这个类中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><br>nodes = [<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;D&#x27;</span>]<br>graph = nx.DiGraph()<br><span class="hljs-keyword">for</span> node <span class="hljs-keyword">in</span> nodes:<br>    graph.add_node(node)<br><br>edges = [(<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>), (<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>), (<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;D&#x27;</span>), (<span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;A&#x27;</span>), (<span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-string">&#x27;D&#x27;</span>), (<span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;A&#x27;</span>), (<span class="hljs-string">&#x27;D&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>), (<span class="hljs-string">&#x27;D&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>)]<br><span class="hljs-keyword">for</span> edge <span class="hljs-keyword">in</span> edges:<br>    graph.add_edge(edge[<span class="hljs-number">0</span>], edge[<span class="hljs-number">1</span>])<br><br>pagerank_dic = nx.pagerank(graph)<br>pagerank_dic<br></code></pre></td></tr></table></figure><p>代码的输出如下(在<code>jupyter notebook</code>中运行)</p><p><img src="image-20221014221358502.png" alt="image-20221014221358502"></p><p>最后的计算结果是一个字典，包含所有链接的<code>PageRank</code>值。</p><h3 id="2-3-计算前面爬取所有网页的PageRank值"><a href="#2-3-计算前面爬取所有网页的PageRank值" class="headerlink" title="2.3 计算前面爬取所有网页的PageRank值"></a>2.3 计算前面爬取所有网页的<code>PageRank</code>值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">import</span> jieba<br><span class="hljs-keyword">import</span> logging<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> warnings<br><span class="hljs-keyword">import</span> networkx <span class="hljs-keyword">as</span> nx<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-comment"># 取消jieba 的日志输出</span><br>jieba.setLogLevel(logging.INFO)<br>warnings.filterwarnings(<span class="hljs-string">&#x27;ignore&#x27;</span>)<br>max_file_num = <span class="hljs-number">2000</span><br>folder_name = <span class="hljs-string">&#x27;../sina&#x27;</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pagerank</span>(<span class="hljs-params">files: <span class="hljs-built_in">list</span></span>):<br>    link_set = [f[<span class="hljs-string">&#x27;link&#x27;</span>] <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> files]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;len of all links: &quot;</span>, <span class="hljs-built_in">len</span>(<span class="hljs-built_in">set</span>(link_set)))<br>    graph = nx.DiGraph()<br>    <span class="hljs-comment"># 循环将所有节点加入图</span><br>    <span class="hljs-keyword">for</span> node <span class="hljs-keyword">in</span> link_set:<br>        graph.add_node(node)<br><span class="hljs-comment"># 循环将所有边加入图</span><br>    <span class="hljs-keyword">for</span> idx, link <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(link_set):<br>        <span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> <span class="hljs-built_in">set</span>(files[idx][<span class="hljs-string">&#x27;hrefs&#x27;</span>]):  <span class="hljs-comment"># 对链接去重</span><br>            <span class="hljs-keyword">if</span> url <span class="hljs-keyword">in</span> link_set:<br>                graph.add_edge(link, url)<br><span class="hljs-comment"># 得到计算结果</span><br>    pagerank_dic = nx.pagerank(graph)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;pagerank_dic: &#x27;</span>, pagerank_dic)<br><br>    all_files = pd.read_csv(<span class="hljs-string">&#x27;../files/all_files.csv&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>)<br>    all_files[<span class="hljs-string">&#x27;pr&#x27;</span>] = <span class="hljs-number">0</span><br>    all_files[<span class="hljs-string">&#x27;pr&#x27;</span>] = all_files[<span class="hljs-string">&#x27;link&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: pagerank_dic.get(x))<br>    all_files.to_csv(<span class="hljs-string">&#x27;../files/all_files.csv&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>, index=<span class="hljs-literal">False</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_pr</span>():<br>    filenames = os.listdir(folder_name)<br>    filenames.sort(key=<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">int</span>(x.split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>]))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;filenames: &#x27;</span>, filenames)<br>    all_files = []<br><span class="hljs-comment"># 读取文件</span><br>    <span class="hljs-keyword">for</span> idx, filename <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tqdm(filenames, desc=<span class="hljs-string">&#x27;读取文件&#x27;</span>)):<br>        <span class="hljs-keyword">try</span>:<br>            path = folder_name + <span class="hljs-string">&#x27;/&#x27;</span> + filename<br>            <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>                file = json.load(f)<br>                all_files.append(file)<br><br>            <span class="hljs-keyword">if</span> idx == max_file_num:<br>                <span class="hljs-keyword">break</span><br>        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>            <span class="hljs-built_in">print</span>(e)<br><br>    pagerank(all_files)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    calculate_pr()<br><br></code></pre></td></tr></table></figure><p>计算的结果保存到<code>files</code>文件夹下的<code>all_files.csv</code>下</p><p><img src="image-20221014222854067.png"></p><p>可以看到现在的<code>csv</code>文件中多了一列<code>pr</code>，为所有网页的<code>pr</code>值。</p><h2 id="3-倒排索引的建立"><a href="#3-倒排索引的建立" class="headerlink" title="3.倒排索引的建立"></a>3.倒排索引的建立</h2><p>之后就可以建立倒排索引了，详情请看。</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从零开始做一个搜索引擎--摘要提取</title>
    <link href="/2022/10/14/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E-%E6%91%98%E8%A6%81%E6%8F%90%E5%8F%96/"/>
    <url>/2022/10/14/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E-%E6%91%98%E8%A6%81%E6%8F%90%E5%8F%96/</url>
    
    <content type="html"><![CDATA[<h1 id="从零开始做一个搜索引擎-摘要提取"><a href="#从零开始做一个搜索引擎-摘要提取" class="headerlink" title="从零开始做一个搜索引擎-摘要提取"></a>从零开始做一个搜索引擎-摘要提取</h1><h2 id="1-为什么要做摘要"><a href="#1-为什么要做摘要" class="headerlink" title="1. 为什么要做摘要"></a>1. 为什么要做摘要</h2><p>自动摘要（Automatic Summarization）的方法主要有两种：Extraction和Abstraction。其中Extraction是抽取式自动文摘方法，通过提取文档中已存在的关键词，句子形成摘要；Abstraction是生成式自动文摘方法，通过建立抽象的语意表示，使用自然语言生成技术，形成摘要。由于自动摘要方法需要复杂的自然语言理解和生成技术支持，应用领域受限，抽取式摘要成为现阶段主流，它也能在很大程度上满足人们对摘要的需求。</p><ul><li>基于统计：统计词频，位置等信息，计算句子权值，再简选取权值高的句子作为文摘，特点：简单易用，但对词句的使用大多仅停留在表面信息。</li><li>基于图模型：构建拓扑结构图，对词句进行排序。例如，TextRank/LexRank</li><li>基于潜在语义：使用主题模型，挖掘词句隐藏信息。例如，采用LDA，HMM</li><li>基于线路规划：将摘要问题转为线路规划，求全局最优解。</li></ul><h2 id="2-使用TextRank提取摘要"><a href="#2-使用TextRank提取摘要" class="headerlink" title="2.使用TextRank提取摘要"></a>2.使用<code>TextRank</code>提取摘要</h2><h3 id="2-1安装textrank4zh包"><a href="#2-1安装textrank4zh包" class="headerlink" title="2.1安装textrank4zh包"></a>2.1安装<code>textrank4zh</code>包</h3><p>在命令行输入<code>pip install textrank4zh</code>即可完成安装</p><h3 id="2-2使用textrank4zh提取摘要"><a href="#2-2使用textrank4zh提取摘要" class="headerlink" title="2.2使用textrank4zh提取摘要"></a>2.2使用<code>textrank4zh</code>提取摘要</h3><p>对text字符串提取两句摘要，代码如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> textrank4zh <span class="hljs-keyword">import</span> TextRank4Sentence<br><br>text = <span class="hljs-string">&#x27;国际舆论本来还在等待和猜测,在今天晚些时候的俄联邦国家安全会议上,普京会否宣布将对乌采取哪些“强硬回击”。不料一大清早,基辅以及乌克兰其他多地几乎同时传来的爆炸声,立即就让人们意识到:乌克兰总统泽连斯基以及其他乌方高官密集发声表示谴责,北约、欧盟和欧洲多国领导人也都第一时间表态支持乌克兰。可想而知,俄方针锋相对地表达了强硬和警告&#x27;</span><br><br>tr4s = TextRank4Sentence()<br>tr4s.analyze(text=text, lower=<span class="hljs-literal">True</span>, source=<span class="hljs-string">&#x27;all_filters&#x27;</span>)<br>tr4s.get_key_sentences(num=<span class="hljs-number">2</span>) <span class="hljs-comment"># num是指定摘要的数量</span><br></code></pre></td></tr></table></figure><p>程序输出如下(此代码在<code>jupyter notebook</code>中运行，所以不加<code>print()</code>语句也能打印输出)</p><p><img src="image-20221014212031142.png" alt="image-20221014212031142"></p><p>可以看到返回了一个列表，列表中包含两个字典，每个字典中的<code>sentence</code>键对应的值就是我们要的摘要。</p><p>由此我们可以封装一个提取摘要的函数，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_summary</span>(<span class="hljs-params">text: <span class="hljs-built_in">str</span>, num: <span class="hljs-built_in">int</span> = <span class="hljs-number">3</span></span>) -&gt; <span class="hljs-built_in">list</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">    :param text: 待提取的字符串</span><br><span class="hljs-string">    :param num:  最多生成的摘要句子数量</span><br><span class="hljs-string">    :return:     摘要句子组成的列表</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    tr4s = TextRank4Sentence()<br>    tr4s.analyze(text=text, lower=<span class="hljs-literal">True</span>, source=<span class="hljs-string">&#x27;all_filters&#x27;</span>)<br>    <span class="hljs-keyword">return</span> [item.sentence <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> tr4s.get_key_sentences(num)]<br></code></pre></td></tr></table></figure><p>通过给这个函数传入字符串和要生成的摘要句子数量，我们可以得到一个由<code>num</code>个句子组成的列表。</p><h3 id="2-3对之前爬取的文章提取摘要"><a href="#2-3对之前爬取的文章提取摘要" class="headerlink" title="2.3对之前爬取的文章提取摘要"></a>2.3对之前爬取的文章提取摘要</h3><p>之前的博客中使用<code>feapder</code><a href="https://0awei0.github.io/2022/09/30/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E-%E7%88%AC%E8%99%AB/">框架爬取新浪新闻</a>，保存的每一个页面的<code>json</code>文件格式如下：</p><p><img src="image-20221014212852057.png" alt="image-20221014212852057"></p><p>网页的标题、正文、链接均被保存在这样的<code>json</code>文件中，如果你已经运行了上一节中的爬虫，那么你会得到一个有2000个json文件的<code>sina</code>文件夹，如下：</p><p><img src="image-20221014213105488.png" alt="image-20221014213105488"></p><p>现在我们在<code>sina</code>文件夹的同一目录，创建一个名为<code>pre_process</code>的文件夹，用于存放我们对爬取的<code>json</code>文件进行处理的一些文件,结构如下:</p><p><img src="image-20221014213356872.png" alt="image-20221014213356872"></p><p><img src="image-20221014213950518.png" alt="image-20221014213950518"></p><p>这篇文章仅用到了提取摘要的文件，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">from</span> textrank4zh <span class="hljs-keyword">import</span> TextRank4Sentence<br><span class="hljs-keyword">import</span> jieba<br><span class="hljs-keyword">import</span> logging<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> warnings<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-comment"># 取消jieba 的日志输出</span><br>jieba.setLogLevel(logging.INFO)<br>warnings.filterwarnings(<span class="hljs-string">&#x27;ignore&#x27;</span>)<br>max_file_num = <span class="hljs-number">2000</span><br>folder_name = <span class="hljs-string">&#x27;../sina&#x27;</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_summary</span>(<span class="hljs-params">text: <span class="hljs-built_in">str</span>, num: <span class="hljs-built_in">int</span> = <span class="hljs-number">3</span></span>) -&gt; <span class="hljs-built_in">list</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">    :param text: 待提取的字符串</span><br><span class="hljs-string">    :param num:  最多生成的摘要句子数量</span><br><span class="hljs-string">    :return:     摘要句子组成的列表</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    tr4s = TextRank4Sentence()<br>    tr4s.analyze(text=text, lower=<span class="hljs-literal">True</span>, source=<span class="hljs-string">&#x27;all_filters&#x27;</span>)<br>    <span class="hljs-keyword">return</span> [item.sentence <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> tr4s.get_key_sentences(num)]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_summary</span>():<br>    filenames = os.listdir(folder_name)  <span class="hljs-comment"># 获取该路径下所有文件名</span><br>    filenames.sort(key=<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">int</span>(x.split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>]))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;filenames: &#x27;</span>, filenames)<br>    all_files = pd.DataFrame()<br><br>    <span class="hljs-keyword">for</span> idx, filename <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tqdm(filenames, desc=<span class="hljs-string">&#x27;生成摘要&#x27;</span>)):<br>        <span class="hljs-keyword">try</span>:<br>            path = folder_name + <span class="hljs-string">&#x27;/&#x27;</span> + filename<br>            <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>                file = json.load(f)<br>                <span class="hljs-keyword">del</span> file[<span class="hljs-string">&#x27;hrefs&#x27;</span>]<br>                file[<span class="hljs-string">&#x27;summary&#x27;</span>] = <span class="hljs-string">&quot; &quot;</span>.join(get_summary(file[<span class="hljs-string">&#x27;content&#x27;</span>], <span class="hljs-number">2</span>))<br>                all_files = all_files.append(pd.Series(file), ignore_index=<span class="hljs-literal">True</span>)<br>            <span class="hljs-keyword">if</span> idx == max_file_num:<br>                <span class="hljs-keyword">break</span><br>        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>            <span class="hljs-built_in">print</span>(e)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;len of all files: &#x27;</span>, <span class="hljs-built_in">len</span>(all_files))<br>    all_files.to_csv(<span class="hljs-string">&#x27;../files/all_files.csv&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>, index=<span class="hljs-literal">False</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    os.makedirs(<span class="hljs-string">&#x27;../files&#x27;</span>, exist_ok=<span class="hljs-literal">True</span>)<br>    generate_summary()<br><br></code></pre></td></tr></table></figure><p>最后生成的摘要保存到<code>files</code>文件夹下的<code>all_files.csv</code>中，我们可以来看看其中保留的内容。</p><p><img src="image-20221014214340325.png" alt="image-20221014214340325"></p><p>这里只展示前10条数据，可以看到，每个网页包含标题、内容、链接和摘要。</p><h2 id="3-PageRank值的计算"><a href="#3-PageRank值的计算" class="headerlink" title="3. PageRank值的计算"></a>3. <code>PageRank</code>值的计算</h2><p>提取了摘要之后，可以进行<code>PageRank</code>值的计算，从而对搜索到的页面进行排序，关于<code>PageRank</code><a href="https://0awei0.github.io/2022/10/14/PageRank%E5%80%BC%E8%AE%A1%E7%AE%97/">的计算可以参照我的下一篇博客</a>。</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从零开始做一个搜索引擎--爬虫实现</title>
    <link href="/2022/09/30/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E-%E7%88%AC%E8%99%AB/"/>
    <url>/2022/09/30/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E-%E7%88%AC%E8%99%AB/</url>
    
    <content type="html"><![CDATA[<h1 id="从零开始做一个搜索引擎–爬虫实现"><a href="#从零开始做一个搜索引擎–爬虫实现" class="headerlink" title="从零开始做一个搜索引擎–爬虫实现"></a>从零开始做一个搜索引擎–爬虫实现</h1><h2 id="1-队列实现"><a href="#1-队列实现" class="headerlink" title="1. 队列实现"></a>1. 队列实现</h2><p>使用广度优先爬取网页需要一个队列辅助存储网页的<code>url</code>，这里实现一个元素单一的队列，方便后续使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Queue</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.elements = []<br>        self.index = <span class="hljs-number">0</span><br><span class="hljs-comment"># 元素出队列</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">dequeue</span>(<span class="hljs-params">self</span>):<br>        element = self.elements[self.index]<br>        self.index += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> element<br><span class="hljs-comment"># 元素入队列</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">enqueue</span>(<span class="hljs-params">self, element</span>):<br>        <span class="hljs-keyword">if</span> element[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>] == <span class="hljs-string">&quot;https&quot;</span> <span class="hljs-keyword">or</span> element[<span class="hljs-number">0</span>:<span class="hljs-number">4</span>] == <span class="hljs-string">&quot;http&quot;</span>:<br>            <span class="hljs-keyword">if</span> element <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> self.elements:<br>                self.elements.append(element)<br><span class="hljs-comment"># 判断队列是否为空</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">isnull</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">if</span> self.index == <span class="hljs-built_in">len</span>(self.elements):<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure><h2 id="2-深度优先与广度优先"><a href="#2-深度优先与广度优先" class="headerlink" title="2.深度优先与广度优先"></a>2.深度优先与广度优先</h2><p><img src="1.jpg" alt="img"></p><p>​                                                                                                       </p><p>若网页结构如上图，深度优先的爬取顺序为：A、B、D、E、I、C、F、G、H（递归实现）</p><p>广度优先的爬取顺序为：A、B、C、D、E、F、G、H、I（队列实现）</p><h2 id="3-广度优先爬取"><a href="#3-广度优先爬取" class="headerlink" title="3.广度优先爬取"></a>3.广度优先爬取</h2><p>所有的爬取均从新浪新闻首页开始，提取每一页的标题、正文、链接，使用上文提到的队列可以很简单的实现广度优先算法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> unicodedata<br><span class="hljs-keyword">from</span> lxml <span class="hljs-keyword">import</span> etree<br><span class="hljs-keyword">from</span> tools <span class="hljs-keyword">import</span> Queue<br><span class="hljs-keyword">import</span> urllib3<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> os<br><br>urllib3.disable_warnings()<br><br><br><span class="hljs-comment"># 广度优先爬取</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">breadth_first</span>():<br>    headers = &#123;<br>        <span class="hljs-string">&#x27;user-agent&#x27;</span>: <span class="hljs-string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) &#x27;</span><br>                      <span class="hljs-string">&#x27;Chrome/105.0.0.0 &#x27;</span><br>                      <span class="hljs-string">&#x27;Safari/537.36 &#x27;</span><br>    &#125;<br><br>    url = <span class="hljs-string">&quot;https://news.sina.com.cn/&quot;</span><br>    resp = requests.get(url, headers=headers, verify=<span class="hljs-literal">False</span>)<br>    tree = etree.HTML(resp.text)<br>    <span class="hljs-comment"># 新浪首页的所有链接</span><br>    href_list = tree.xpath(<span class="hljs-string">&#x27;//a/@href&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(href_list)<br>    queue = Queue()<br>    <span class="hljs-comment"># 新浪首页的所有链接首先入队列</span><br>    <span class="hljs-keyword">for</span> href <span class="hljs-keyword">in</span> href_list:<br>        queue.enqueue(href)<br><br>    i = <span class="hljs-number">1</span><br>    <span class="hljs-comment"># 队列不为空则继续循环</span><br>    <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> queue.isnull():<br>        <span class="hljs-keyword">try</span>:<br>            <span class="hljs-comment"># 队头元素出队</span><br>            url = queue.dequeue()<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;crawling &quot;</span>, url)<br><br>            resp = requests.get(url, headers=headers, verify=<span class="hljs-literal">False</span>)<br>            text = resp.text.encode(resp.encoding).decode(resp.apparent_encoding)<br><br>            <span class="hljs-comment"># resp.encoding = &#x27;utf-8&#x27;</span><br>            tree = etree.HTML(text)<br><br>            <span class="hljs-comment"># 提取标题</span><br>            title = tree.xpath(<span class="hljs-string">&#x27;//h1[@class=&quot;main-title&quot;]/text()&#x27;</span>)<br>            title = <span class="hljs-string">&quot;&quot;</span>.join(title)<br><br>            contents = tree.xpath(<span class="hljs-string">&#x27;//div[@id=&quot;article&quot;]//p/text()&#x27;</span>)<br>            contents = [unicodedata.normalize(<span class="hljs-string">&#x27;NFKC&#x27;</span>, i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> contents]<br>            <span class="hljs-comment"># 提取正文</span><br>            content = <span class="hljs-string">&quot;&quot;</span>.join(contents)<br>            <span class="hljs-keyword">if</span> title == <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">or</span> content == <span class="hljs-string">&#x27;&#x27;</span>:<br>                <span class="hljs-keyword">continue</span><br><br>            data = &#123;<br>                <span class="hljs-string">&#x27;title&#x27;</span>: title,<br>                <span class="hljs-string">&#x27;content&#x27;</span>: content,<br>                <span class="hljs-string">&#x27;url&#x27;</span>: url<br>            &#125;<br>            <span class="hljs-comment"># 将标题，正文，链接写入json文件</span><br>            <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;html_breadth_first/&#x27;</span> + <span class="hljs-built_in">str</span>(i) + <span class="hljs-string">&#x27;.json&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>, mode=<span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>                f.write(json.dumps(data, indent=<span class="hljs-number">4</span>, ensure_ascii=<span class="hljs-literal">False</span>))<br>            <span class="hljs-comment"># 提取链接</span><br>            hrefs = tree.xpath(<span class="hljs-string">&#x27;//a/@href&#x27;</span>)<br>            <span class="hljs-comment"># 新的链接入队列</span><br>            <span class="hljs-keyword">for</span> href <span class="hljs-keyword">in</span> hrefs:<br>                queue.enqueue(href)<br>            i += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">2000</span>:  <span class="hljs-comment"># 爬取2000个网页则停止</span><br>                <span class="hljs-keyword">break</span><br>        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>            <span class="hljs-built_in">print</span>(e)<br>            <span class="hljs-keyword">pass</span><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    os.makedirs(<span class="hljs-string">&quot;html_breadth_first&quot;</span>, exist_ok=<span class="hljs-literal">True</span>)<br>    breadth_first()<br><br></code></pre></td></tr></table></figure><h2 id="4-深度优先爬取"><a href="#4-深度优先爬取" class="headerlink" title="4.深度优先爬取"></a>4.深度优先爬取</h2><p>深度优先采取递归的方式实现，也可使用栈，这里只给出递归的实现方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> unicodedata<br><span class="hljs-keyword">from</span> lxml <span class="hljs-keyword">import</span> etree<br><span class="hljs-keyword">import</span> urllib3<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> os<br><br>urllib3.disable_warnings()<br><br>exist_urls = []<br>num_pages = <span class="hljs-number">0</span><br>num_news = <span class="hljs-number">0</span><br>max_depth = <span class="hljs-number">10</span><br>max_news_num = <span class="hljs-number">1000</span><br>flag = <span class="hljs-number">0</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">crawler</span>(<span class="hljs-params">url, depth=<span class="hljs-number">1</span></span>):<br>    <span class="hljs-keyword">global</span> num_pages, num_news<br>    <span class="hljs-keyword">global</span> exist_urls<br>    <span class="hljs-keyword">global</span> max_depth, flag<br>    exist_urls.append(url)<br>    <span class="hljs-keyword">if</span> num_news == max_news_num <span class="hljs-keyword">or</span> flag &gt;= <span class="hljs-number">20</span>:<br>        <span class="hljs-keyword">return</span><br>    headers = &#123;<br>        <span class="hljs-string">&#x27;user-agent&#x27;</span>: <span class="hljs-string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) &#x27;</span><br>                      <span class="hljs-string">&#x27;Chrome/105.0.0.0 &#x27;</span><br>                      <span class="hljs-string">&#x27;Safari/537.36 &#x27;</span><br>    &#125;<br>    <span class="hljs-keyword">if</span> url[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>] == <span class="hljs-string">&quot;https&quot;</span> <span class="hljs-keyword">or</span> url[<span class="hljs-number">0</span>:<span class="hljs-number">4</span>] == <span class="hljs-string">&quot;http&quot;</span>:<br>        <span class="hljs-keyword">try</span>:<br>            num_pages += <span class="hljs-number">1</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;正在爬取第&quot;</span>, num_pages, <span class="hljs-string">&quot;个网页&quot;</span>, <span class="hljs-string">&quot;深度为&quot;</span>, depth, url)<br><br>            resp = requests.get(url, headers=headers, verify=<span class="hljs-literal">False</span>, timeout=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br>            resp.encoding = <span class="hljs-string">&#x27;utf-8&#x27;</span><br>            tree = etree.HTML(resp.text)<br><br>            <span class="hljs-comment"># 提取标题</span><br>            title = tree.xpath(<span class="hljs-string">&#x27;//h1[@class=&quot;main-title&quot;]/text()&#x27;</span>)<br>            contents = tree.xpath(<span class="hljs-string">&#x27;//div[@id=&quot;article&quot;]//p/text()&#x27;</span>)<br>            contents = [unicodedata.normalize(<span class="hljs-string">&#x27;NFKC&#x27;</span>, i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> contents]<br>            <span class="hljs-comment"># 提取正文</span><br>            content = <span class="hljs-string">&quot;&quot;</span>.join(contents)<br>            <span class="hljs-keyword">if</span> title == <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">or</span> content == <span class="hljs-string">&#x27;&#x27;</span>:<br>                flag += <span class="hljs-number">1</span><br>                <span class="hljs-keyword">pass</span><br>            <span class="hljs-keyword">else</span>:<br>                data = &#123;<br>                    <span class="hljs-string">&#x27;title&#x27;</span>: title,<br>                    <span class="hljs-string">&#x27;content&#x27;</span>: content,<br>                    <span class="hljs-string">&#x27;url&#x27;</span>: url<br>                &#125;<br>                num_news += <span class="hljs-number">1</span><br>                <span class="hljs-comment"># 将标题，正文，链接写入json文件</span><br>                <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;html_depth_first/&#x27;</span> + <span class="hljs-built_in">str</span>(num_news) + <span class="hljs-string">&#x27;.json&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>, mode=<span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>                    f.write(json.dumps(data, indent=<span class="hljs-number">4</span>, ensure_ascii=<span class="hljs-literal">False</span>))<br><br>            <span class="hljs-comment"># 提取链接</span><br>            hrefs = tree.xpath(<span class="hljs-string">&#x27;//a/@href&#x27;</span>)<br>            unique_urls = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(hrefs) - <span class="hljs-built_in">set</span>(exist_urls))<br>            <span class="hljs-keyword">for</span> unique_url <span class="hljs-keyword">in</span> unique_urls:<br>                <span class="hljs-keyword">if</span> depth &lt; max_depth:<br>                    crawler(unique_url, depth + <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>            <span class="hljs-built_in">print</span>(e)<br>            <span class="hljs-keyword">pass</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">depth_first</span>():<br>    <span class="hljs-keyword">global</span> exist_urls, flag<br><br>    headers = &#123;<br>        <span class="hljs-string">&#x27;user-agent&#x27;</span>: <span class="hljs-string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) &#x27;</span><br>                      <span class="hljs-string">&#x27;Chrome/105.0.0.0 &#x27;</span><br>                      <span class="hljs-string">&#x27;Safari/537.36 &#x27;</span><br>    &#125;<br>    url = <span class="hljs-string">&quot;https://news.sina.com.cn/&quot;</span><br>    resp = requests.get(url, headers=headers, verify=<span class="hljs-literal">False</span>)<br>    tree = etree.HTML(resp.text)<br>    <span class="hljs-comment"># 新浪首页的所有链接</span><br>    href_list = tree.xpath(<span class="hljs-string">&#x27;//a/@href&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(href_list)<br>    exist_urls += <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(href_list))<br>    <span class="hljs-keyword">for</span> href <span class="hljs-keyword">in</span> href_list:<br>        flag = <span class="hljs-number">0</span><br>        crawler(href, depth=<span class="hljs-number">2</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    os.makedirs(<span class="hljs-string">&quot;html_depth_first&quot;</span>, exist_ok=<span class="hljs-literal">True</span>)<br>    depth_first()<br><br></code></pre></td></tr></table></figure><h2 id="5-使用feapder框架加速爬取"><a href="#5-使用feapder框架加速爬取" class="headerlink" title="5.使用feapder框架加速爬取"></a>5.使用<code>feapder</code>框架加速爬取</h2><p><code>feapder</code>框架是一个开源的爬虫框架，<a href="https://boris-code.gitee.io/feapder/#/usage/AirSpider">官方链接</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> chardet<br><span class="hljs-keyword">import</span> feapder<br><span class="hljs-keyword">import</span> unicodedata<br><span class="hljs-keyword">from</span> lxml <span class="hljs-keyword">import</span> etree<br><span class="hljs-keyword">from</span> feapder <span class="hljs-keyword">import</span> setting<br><span class="hljs-keyword">import</span> urllib3<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> threading<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-comment"># 去除警告</span><br>urllib3.disable_warnings()<br><span class="hljs-comment"># 设置爬虫最大重试次数为0，即不重试</span><br>setting.SPIDER_MAX_RETRY_TIMES = <span class="hljs-number">0</span><br><span class="hljs-comment"># 已经爬取的页面数量</span><br>num_pages = <span class="hljs-number">0</span><br><span class="hljs-comment"># 存放json文件的文件夹名字，这里是上一级目录的sina文件夹</span><br>folder_name = <span class="hljs-string">&#x27;../sina&#x27;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">多线程访问同一个全局变量可能造成变量值错误，解决办法如下（参照https://blog.csdn.net/m0_37886429/article/details/102895759）</span><br><span class="hljs-string"></span><br><span class="hljs-string">threading.Condition 可以在没有数据的时候处于阻塞等待状态，一旦有了合适的数据，可以使用 notify 相关的函数来通知其他等待的线程。</span><br><span class="hljs-string">这样可以不用做一些无用的上锁和解锁的操作，提高程序的性能。threading.Condition类似threading.Lock，可以在修改全局数据的时候进行上锁，</span><br><span class="hljs-string">也可以在修改完毕后进行解锁。</span><br><span class="hljs-string"></span><br><span class="hljs-string">acquire：上锁。</span><br><span class="hljs-string">release：解锁。</span><br><span class="hljs-string">wait：将当前线程处于等待状态，并且会释放锁。可以被其他线程使用notify和notify_all函数唤醒。被唤醒后会继续等待上锁，上锁后继续执行下面的代码。</span><br><span class="hljs-string">notify：通知某个正在等待的线程，默认是第1个等待的线程。</span><br><span class="hljs-string">notify_all：通知所有正在等待的线程。notify和notify_all不会释放锁。并且需要在release之前调用</span><br><span class="hljs-string"></span><br><span class="hljs-string">cLock = threading.Condition()</span><br><span class="hljs-string">cLock.acquire()</span><br><span class="hljs-string">修改变量</span><br><span class="hljs-string">cLock.notify_all()  # 通知wait()</span><br><span class="hljs-string">cLock.release()</span><br><span class="hljs-string">time.sleep(0.1)</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>cLock = threading.Condition()<br><span class="hljs-comment"># 最大爬取的页面数量</span><br>max_pages = <span class="hljs-number">10</span><br><span class="hljs-comment"># 列表中存在的url</span><br>exist_urls = []<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">AirSpiderTest</span>(feapder.AirSpider):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">start_requests</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">yield</span> feapder.Request(<span class="hljs-string">&quot;https://news.sina.com.cn/&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">parse</span>(<span class="hljs-params">self, request, response</span>):<br>        <span class="hljs-keyword">global</span> exist_urls<br><br>        text = response.text<br>        tree = etree.HTML(text)<br>        <span class="hljs-comment"># 新浪首页的所有链接</span><br>        href_list = tree.xpath(<span class="hljs-string">&#x27;//a/@href&#x27;</span>)<br>        href_list = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(href_list))<br>        exist_urls += href_list<br>        <span class="hljs-keyword">for</span> href <span class="hljs-keyword">in</span> href_list:<br>            <span class="hljs-keyword">yield</span> feapder.Request(href, callback=self.parser_news)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">parser_news</span>(<span class="hljs-params">self, request, response</span>):<br>        <span class="hljs-keyword">global</span> num_pages, exist_urls<br>        <span class="hljs-keyword">if</span> response.encoding.lower() != <span class="hljs-string">&#x27;utf-8&#x27;</span>:<br>            <span class="hljs-keyword">raise</span> Exception(<span class="hljs-string">&quot;encoding  error&quot;</span>)<br><br>        text = response.text<br>        tree = etree.HTML(text)<br><br>        titles = tree.xpath(<span class="hljs-string">&#x27;//h1[@class=&quot;main-title&quot;]/text()&#x27;</span>)  <span class="hljs-comment"># 获得标题的列表</span><br>        contents = tree.xpath(<span class="hljs-string">&#x27;//div[@id=&quot;article&quot;]//p/text()&#x27;</span>)  <span class="hljs-comment"># 获取正文的列表</span><br>        contents = [unicodedata.normalize(<span class="hljs-string">&#x27;NFKC&#x27;</span>, i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> contents]  <span class="hljs-comment"># 解码一些字符</span><br>        title = <span class="hljs-string">&quot;&quot;</span>.join(titles)  <span class="hljs-comment"># 拼接标题</span><br>        content = <span class="hljs-string">&quot;&quot;</span>.join(contents)  <span class="hljs-comment"># 拼接正文</span><br><br>        <span class="hljs-keyword">if</span> title == <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">or</span> content == <span class="hljs-string">&#x27;&#x27;</span>:  <span class="hljs-comment"># 若正文或标题为空，则抛出异常，不保存此网页内容</span><br>            <span class="hljs-keyword">raise</span> Exception(<span class="hljs-string">&quot;content is null&quot;</span>)<br>        <span class="hljs-keyword">else</span>:<br>            hrefs = tree.xpath(<span class="hljs-string">&#x27;//a/@href&#x27;</span>)  <span class="hljs-comment"># 提取链接</span><br>            hrefs = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(hrefs))  <span class="hljs-comment"># 去重</span><br><br>            data = &#123;  <span class="hljs-comment"># 要保存的json文件</span><br>                <span class="hljs-string">&#x27;title&#x27;</span>: title.strip(),  <span class="hljs-comment"># 当前页面的标题</span><br>                <span class="hljs-string">&#x27;content&#x27;</span>: content.strip(),  <span class="hljs-comment"># 当前页面的内容</span><br>                <span class="hljs-string">&#x27;link&#x27;</span>: request.url,  <span class="hljs-comment"># 当前页面的链接</span><br>                <span class="hljs-string">&#x27;hrefs&#x27;</span>: hrefs  <span class="hljs-comment"># 当前页面包含的链接, 记录用于后面计算PageRank值</span><br>            &#125;<br><br>            cLock.acquire()<br>            <span class="hljs-comment"># 保存文件</span><br>            <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(folder_name + <span class="hljs-string">&quot;/&quot;</span> + <span class="hljs-built_in">str</span>(num_pages) + <span class="hljs-string">&#x27;.json&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>, mode=<span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>                f.write(json.dumps(data, indent=<span class="hljs-number">4</span>, ensure_ascii=<span class="hljs-literal">False</span>))<br><br>            num_pages += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> num_pages == max_pages:  <span class="hljs-comment"># 达到指定数量，直接退出程序</span><br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;爬取页面数量已到达设定最大值！&quot;</span>)<br>                os._exit(<span class="hljs-number">0</span>)<br><br>            cLock.notify_all()  <span class="hljs-comment"># 通知wait()</span><br>            cLock.release()<br>            time.sleep(<span class="hljs-number">0.1</span>)<br><br>            unique_urls = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(hrefs) - <span class="hljs-built_in">set</span>(exist_urls))  <span class="hljs-comment"># 提取未爬取过的链接</span><br>            exist_urls += unique_urls<br>            <span class="hljs-comment"># 未爬取的链接继续爬取</span><br>            <span class="hljs-keyword">for</span> unique_url <span class="hljs-keyword">in</span> unique_urls:<br>                <span class="hljs-keyword">yield</span> feapder.Request(unique_url, callback=self.parser_news)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">validate</span>(<span class="hljs-params">self, request, response</span>):<br>        <span class="hljs-keyword">if</span> response.status_code != <span class="hljs-number">200</span>:<br>            <span class="hljs-keyword">raise</span> Exception(<span class="hljs-string">&quot;response code not 200&quot;</span>)  <span class="hljs-comment"># 抛出异常</span><br><br>    <span class="hljs-comment"># 下载中间件用于在请求之前，对请求做一些处理，如添加cookie、header等。写法如下：</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">download_midware</span>(<span class="hljs-params">self, request</span>):<br>        request.timeout = (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)<br>        <span class="hljs-keyword">return</span> request<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    os.makedirs(folder_name, exist_ok=<span class="hljs-literal">True</span>)<br>    AirSpiderTest(thread_count=<span class="hljs-number">8</span>).start()<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>爬虫</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>垃圾分类小demo</title>
    <link href="/2022/07/19/%E5%9E%83%E5%9C%BE%E5%88%86%E7%B1%BB%E5%B0%8Fdemo/"/>
    <url>/2022/07/19/%E5%9E%83%E5%9C%BE%E5%88%86%E7%B1%BB%E5%B0%8Fdemo/</url>
    
    <content type="html"><![CDATA[<h2 id="1-环境搭建"><a href="#1-环境搭建" class="headerlink" title="1. 环境搭建"></a>1. 环境搭建</h2><p>使用的环境为pytorch1.11，直接去官网即可下载<a href="https://pytorch.org/">PyTorch</a>，去官网选择你需要的配置，直接复制命令在命令行进行粘贴即可：</p><p><img src="1.png" alt="image-20220719092532904"></p><h2 id="2-数据准备"><a href="#2-数据准备" class="headerlink" title="2. 数据准备"></a>2. 数据准备</h2><h3 id="2-1-数据格式"><a href="#2-1-数据格式" class="headerlink" title="2.1 数据格式"></a>2.1 数据格式</h3><p><img src="2.png" alt="image-20220719092638421"></p><p>数据集中共有厨余垃圾，可回收物，其他垃圾，有害垃圾四种垃圾，每种垃圾各有11种，一共有44个小类，代码放在code文件夹中，与数据集放在同一文件目录下。</p><p><img src="3.png" alt="image-20220719092833905"></p><h3 id="2-2-划分数据集"><a href="#2-2-划分数据集" class="headerlink" title="2.2 划分数据集"></a>2.2 划分数据集</h3><p>找到了数据集之后我们需要把数据集划分为训练集和测试集，建立dataset.py文件，具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> shutil <span class="hljs-keyword">import</span> copy<br><span class="hljs-keyword">import</span> random<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mkfile</span>(<span class="hljs-params">file</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(file):<br>        os.makedirs(file)<br><br><span class="hljs-comment">#你自己的数据集路径</span><br>file_path = <span class="hljs-string">&quot;../数据集//&quot;</span><br>garbage_class = os.listdir(<span class="hljs-string">&quot;../数据集&quot;</span>)<br><br><span class="hljs-comment"># 创建 训练集train 文件夹，并由5种类名在其目录下创建5个子目录</span><br>mkfile(<span class="hljs-string">&#x27;../data/train&#x27;</span>)<br><span class="hljs-keyword">for</span> cla <span class="hljs-keyword">in</span> garbage_class:<br>    mkfile(<span class="hljs-string">&#x27;../data/train/&#x27;</span> + cla)<br><br><span class="hljs-comment"># 创建 验证集val 文件夹，并由5种类名在其目录下创建5个子目录</span><br>mkfile(<span class="hljs-string">&#x27;../data/val&#x27;</span>)<br><span class="hljs-keyword">for</span> cla <span class="hljs-keyword">in</span> garbage_class:<br>    mkfile(<span class="hljs-string">&#x27;../data/val/&#x27;</span> + cla)<br><br><span class="hljs-comment"># 划分比例，训练集 : 验证集 = 9 : 1</span><br>split_rate = <span class="hljs-number">0.1</span><br><br><span class="hljs-comment"># 遍历5种花的全部图像并按比例分成训练集和验证集</span><br><span class="hljs-keyword">for</span> cla <span class="hljs-keyword">in</span> garbage_class:<br>    cla_path = file_path + <span class="hljs-string">&#x27;/&#x27;</span> + cla + <span class="hljs-string">&#x27;/&#x27;</span>  <span class="hljs-comment"># 某一类别花的子目录</span><br>    images = os.listdir(cla_path)  <span class="hljs-comment"># iamges 列表存储了该目录下所有图像的名称</span><br>    num = <span class="hljs-built_in">len</span>(images)<br>    eval_index = random.sample(images, k=<span class="hljs-built_in">int</span>(num * split_rate))  <span class="hljs-comment"># 从images列表中随机抽取 k 个图像名称</span><br>    <span class="hljs-keyword">for</span> index, image <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(images):<br>        <span class="hljs-comment"># eval_index 中保存验证集val的图像名称</span><br>        <span class="hljs-keyword">if</span> image <span class="hljs-keyword">in</span> eval_index:<br>            image_path = cla_path + image<br>            new_path = <span class="hljs-string">&#x27;../data/val/&#x27;</span> + cla<br>            copy(image_path, new_path)  <span class="hljs-comment"># 将选中的图像复制到新路径</span><br><br>        <span class="hljs-comment"># 其余的图像保存在训练集train中</span><br>        <span class="hljs-keyword">else</span>:<br>            image_path = cla_path + image<br>            new_path = <span class="hljs-string">&#x27;../data/train/&#x27;</span> + cla<br>            copy(image_path, new_path)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\r[&#123;&#125;] processing [&#123;&#125;/&#123;&#125;]&quot;</span>.<span class="hljs-built_in">format</span>(cla, index + <span class="hljs-number">1</span>, num), end=<span class="hljs-string">&quot;&quot;</span>)  <span class="hljs-comment"># processing bar</span><br>    <span class="hljs-built_in">print</span>()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;processing done!&quot;</span>)<br></code></pre></td></tr></table></figure><p>划分好的数据集如下：</p><p><img src="4.png" alt="image-20220719093314655"></p><h2 id="3-模型训练"><a href="#3-模型训练" class="headerlink" title="3. 模型训练"></a>3. 模型训练</h2><h3 id="3-1-数据增强"><a href="#3-1-数据增强" class="headerlink" title="3.1 数据增强"></a>3.1 数据增强</h3><p>数据增强可以有效避免过拟合，使用torchvision中的transforms可以方便的对训练集数据进行数据增强，常见的数据增强方法有旋转，剪切等，本文采用简单的裁剪和翻转。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入包</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms, datasets<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-comment"># 使用GPU训练</span><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br><span class="hljs-built_in">print</span>(device)<br><br>data_transform = &#123;<br>    <span class="hljs-string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="hljs-number">224</span>),  <span class="hljs-comment"># 随机裁剪，再缩放成 224×224</span><br>                                 transforms.RandomHorizontalFlip(p=<span class="hljs-number">0.5</span>),  <span class="hljs-comment"># 水平方向随机翻转，概率为 0.5, 即一半的概率翻转, 一半的概率不翻转</span><br>                                 transforms.RandomHorizontalFlip(<span class="hljs-number">0.5</span>),<br>                                 transforms.ToTensor(),<br>                                 transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))]),<br><br>    <span class="hljs-string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize((<span class="hljs-number">224</span>, <span class="hljs-number">224</span>)),  <span class="hljs-comment"># cannot 224, must (224, 224)</span><br>                               transforms.ToTensor(),<br>                               transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))])&#125;<br></code></pre></td></tr></table></figure><h3 id="3-2-创建DataLoader"><a href="#3-2-创建DataLoader" class="headerlink" title="3.2 创建DataLoader"></a>3.2 创建DataLoader</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br><span class="hljs-comment"># 获取图像数据集的路径</span><br>image_path = <span class="hljs-string">&quot;../data/&quot;</span>  <span class="hljs-comment">#garbage data_set path</span><br><br><span class="hljs-comment"># 导入训练集并进行预处理</span><br>train_dataset = datasets.ImageFolder(root=image_path + <span class="hljs-string">&quot;/train&quot;</span>,<br>                                     transform=data_transform[<span class="hljs-string">&quot;train&quot;</span>])<br>train_num = <span class="hljs-built_in">len</span>(train_dataset)<br><br><span class="hljs-comment"># 按batch_size分批次加载训练集</span><br>train_loader = DataLoader(train_dataset,  <span class="hljs-comment"># 导入的训练集</span><br>                          batch_size=<span class="hljs-number">16</span>,  <span class="hljs-comment"># 每批训练的样本数</span><br>                          shuffle=<span class="hljs-literal">True</span>,  <span class="hljs-comment"># 是否打乱训练集</span><br>                          num_workers=<span class="hljs-number">0</span>)  <span class="hljs-comment"># 使用线程数</span><br>                          <br><span class="hljs-comment"># 导入验证集并进行预处理</span><br>validate_dataset = datasets.ImageFolder(root=image_path + <span class="hljs-string">&quot;/val&quot;</span>,<br>                                        transform=data_transform[<span class="hljs-string">&quot;val&quot;</span>])<br>val_num = <span class="hljs-built_in">len</span>(validate_dataset)<br><br><span class="hljs-comment"># 加载验证集</span><br>validate_loader = torch.utils.data.DataLoader(validate_dataset,  <span class="hljs-comment"># 导入的验证集</span><br>                                              batch_size=<span class="hljs-number">16</span>,<br>                                              shuffle=<span class="hljs-literal">True</span>,<br>                                              num_workers=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><h3 id="3-3-对数据集标签进行映射"><a href="#3-3-对数据集标签进行映射" class="headerlink" title="3.3 对数据集标签进行映射"></a>3.3 对数据集标签进行映射</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">garbage_list = train_dataset.class_to_idx<br>class_dict = <span class="hljs-built_in">dict</span>((val, key) <span class="hljs-keyword">for</span> key, val <span class="hljs-keyword">in</span> garbage_list.items())<br><br><span class="hljs-comment"># 将 class_dict 写入 json 文件中</span><br>json_str = json.dumps(class_dict, indent=<span class="hljs-number">4</span>, ensure_ascii=<span class="hljs-literal">False</span>)<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;class_indices.json&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> json_file:<br>    json_file.write(json_str)<br></code></pre></td></tr></table></figure><p>生成的class_indices.json文件如下：</p><p><img src="5.png" alt="image-20220719093835515"></p><p>包含0~44个垃圾的类型索引，此文件主要用于后续推理时使用，对应出垃圾类别。</p><h3 id="3-4-模型选择"><a href="#3-4-模型选择" class="headerlink" title="3.4 模型选择"></a>3.4 模型选择</h3><p>本文选择在ImageNet上预训练的efficientnet_b1进行迁移学习，这个网络的大小只有30多MB，虽然效果还不错，但如果要追求更高的精度，且有大显存的GPU，可以考虑采用更大的网络（如efficientnet_b7）进行训练，可以得到更好的效果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br>net = torchvision.models.efficientnet_b1(pretrained=<span class="hljs-literal">True</span>)<br>net.to(device)  <span class="hljs-comment"># 分配网络到指定的设备（GPU/CPU）训练</span><br>loss_function = nn.CrossEntropyLoss()  <span class="hljs-comment"># 交叉熵损失</span><br>optimizer = optim.Adam(net.parameters(), lr=<span class="hljs-number">0.0002</span>)  <span class="hljs-comment"># 优化器（训练参数，学习率）</span><br><br>save_path = <span class="hljs-string">&#x27;model.pth&#x27;</span><br>best_acc = <span class="hljs-number">0.0</span><br>test_accs = []<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    net.train()  <span class="hljs-comment"># 训练过程中开启 Dropout</span><br>    running_loss = <span class="hljs-number">0.0</span>  <span class="hljs-comment"># 每个 epoch 都会对 running_loss  清零</span><br>    time_start = time.perf_counter()  <span class="hljs-comment"># 对训练一个 epoch 计时</span><br><br>    step = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> step, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader, start=<span class="hljs-number">0</span>):  <span class="hljs-comment"># 遍历训练集，step从0开始计算</span><br>        images, labels = data  <span class="hljs-comment"># 获取训练集的图像和标签</span><br>        optimizer.zero_grad()  <span class="hljs-comment"># 清除历史梯度</span><br><br>        outputs = net(images.to(device))  <span class="hljs-comment"># 正向传播</span><br>        loss = loss_function(outputs, labels.to(device))  <span class="hljs-comment"># 计算损失</span><br>        loss.backward()  <span class="hljs-comment"># 反向传播</span><br>        optimizer.step()  <span class="hljs-comment"># 优化器更新参数</span><br>        running_loss += loss.item()<br><br>        <span class="hljs-comment"># 打印训练进度（使训练过程可视化）</span><br>        rate = (step + <span class="hljs-number">1</span>) / <span class="hljs-built_in">len</span>(train_loader)  <span class="hljs-comment"># 当前进度 = 当前step / 训练一轮epoch所需总step</span><br>        a = <span class="hljs-string">&quot;*&quot;</span> * <span class="hljs-built_in">int</span>(rate * <span class="hljs-number">50</span>)<br>        b = <span class="hljs-string">&quot;.&quot;</span> * <span class="hljs-built_in">int</span>((<span class="hljs-number">1</span> - rate) * <span class="hljs-number">50</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\rtrain loss: &#123;:^3.0f&#125;%[&#123;&#125;-&gt;&#123;&#125;]&#123;:.3f&#125;&quot;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">int</span>(rate * <span class="hljs-number">100</span>), a, b, loss), end=<span class="hljs-string">&quot;&quot;</span>)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%f s&#x27;</span> % (time.perf_counter() - time_start))<br><br>    <span class="hljs-comment">########################################### validate ###########################################</span><br>    net.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment"># 验证过程中关闭 Dropout</span><br><br>    acc = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> val_data <span class="hljs-keyword">in</span> tqdm(validate_loader):<br>            val_images, val_labels = val_data<br>            outputs = net(val_images.to(device))<br>            predict_y = torch.<span class="hljs-built_in">max</span>(outputs, dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>]  <span class="hljs-comment"># 以output中值最大位置对应的索引（标签）作为预测输出</span><br>            acc += (predict_y == val_labels.to(device)).<span class="hljs-built_in">sum</span>().item()<br>        val_accurate = acc / val_num<br>        test_accs.append(val_accurate)<br><br>        <span class="hljs-comment"># 保存准确率最高的那次网络参数</span><br>        <span class="hljs-keyword">if</span> val_accurate &gt; best_acc:<br>            best_acc = val_accurate<br>            torch.save(net.state_dict(), save_path)<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[epoch %d] train_loss: %.3f test_accuracy: %.3f \n&#x27;</span> %<br>              (epoch + <span class="hljs-number">1</span>, running_loss / step, val_accurate))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Finished Training&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="3-5-精度可视化"><a href="#3-5-精度可视化" class="headerlink" title="3.5 精度可视化"></a>3.5 精度可视化</h3><p>部分训练结果如下</p><p><img src="7.png" alt="image-20220719143216553"></p><p>作出测试集acc曲线：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>plt.ylim(<span class="hljs-number">0.9</span>, <span class="hljs-number">1</span>)<br>x = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">11</span>))<br><br>plt.plot(x, test_accs, label=<span class="hljs-string">&quot;test set acc&quot;</span>)<br><br>plt.legend()  <span class="hljs-comment"># 显示图例</span><br>plt.xticks(x)<br>plt.xlabel(<span class="hljs-string">&quot;epoch&quot;</span>)  <span class="hljs-comment"># X轴标签</span><br>plt.ylabel(<span class="hljs-string">&quot;%acc&quot;</span>)  <span class="hljs-comment"># Y轴标签</span><br>plt.title(<span class="hljs-string">&#x27;acc&#x27;</span>)<br>plt.savefig(<span class="hljs-string">&quot;acc.jpg&quot;</span>)<br></code></pre></td></tr></table></figure><p><img src="6.png" alt="image-20220719143043111"></p><p>仅训练10个epoch，acc就达到了0.977 ， 增大epoch应该还可以提高acc，但由于这里显卡不太行，所以只跑了10个epoch，后续可以考虑增大epoch，让网络达到收敛。</p><h2 id="4-预测图片"><a href="#4-预测图片" class="headerlink" title="4. 预测图片"></a>4. 预测图片</h2><p>打开文件系统，选择一张图片进行预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> tkinter<br><span class="hljs-keyword">from</span> tkinter <span class="hljs-keyword">import</span> filedialog<br><span class="hljs-keyword">import</span> torchvision<br><br><span class="hljs-comment"># 预处理</span><br>data_transform = transforms.Compose(<br>    [transforms.Resize((<span class="hljs-number">224</span>, <span class="hljs-number">224</span>)),<br>     transforms.ToTensor(),<br>     transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))])<br><br>window = tkinter.Tk()<br>window.withdraw()<br>img_file_path = filedialog.askopenfilename()  <span class="hljs-comment"># 获得选择好的文件</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Filepath:&#x27;</span>, img_file_path)<br><br><span class="hljs-comment"># load image</span><br>img = Image.<span class="hljs-built_in">open</span>(img_file_path)<br>plt.imshow(img)<br><span class="hljs-comment"># [N, C, H, W]</span><br>img = data_transform(img)<br><span class="hljs-comment"># expand batch dimension</span><br>img = torch.unsqueeze(img, dim=<span class="hljs-number">0</span>)<br><br>class_indict = <span class="hljs-literal">None</span><br><br><span class="hljs-comment"># read class_indict</span><br><span class="hljs-keyword">try</span>:<br>    json_file = <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;./class_indices.json&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>)<br>    class_indict = json.load(json_file)<br><span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>    <span class="hljs-built_in">print</span>(e)<br>    exit(-<span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># create model</span><br>model = torchvision.models.efficientnet_b1(pretrained=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># load model weights</span><br>model_weight_path = <span class="hljs-string">&quot;model.pth&quot;</span><br>model.load_state_dict(torch.load(model_weight_path))<br><br><span class="hljs-comment"># 关闭 Dropout</span><br>model.<span class="hljs-built_in">eval</span>()<br><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-comment"># predict class</span><br>    output = torch.squeeze(model(img))  <span class="hljs-comment"># 将输出压缩，即压缩掉 batch 这个维度</span><br>    predict = torch.softmax(output, dim=<span class="hljs-number">0</span>)<br>    predict_cla = torch.argmax(predict).numpy()<br><br><span class="hljs-built_in">print</span>(class_indict[<span class="hljs-built_in">str</span>(predict_cla)], predict[predict_cla].item())<br>plt.show()<br><br></code></pre></td></tr></table></figure><p><img src="8.png" alt="image-20220719145611043"></p><p>预测结果为：<img src="9.png" alt="image-20220719145633757"></p><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><p>这次用pytorch实现了一个简单的垃圾分类小demo，后续可以编写交互界面，增大训练集，进一步完善。</p>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>疫情微博情感识别</title>
    <link href="/2022/07/05/bert%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"/>
    <url>/2022/07/05/bert%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="零基础入门NLP赛事"><a href="#零基础入门NLP赛事" class="headerlink" title="零基础入门NLP赛事"></a>零基础入门NLP赛事</h1><h2 id="1-报名比赛"><a href="#1-报名比赛" class="headerlink" title="1. 报名比赛"></a>1. 报名比赛</h2><h3 id="1-1链接：-http-challenge-xfyun-cn-topic-info-type-epidemic-weibo"><a href="#1-1链接：-http-challenge-xfyun-cn-topic-info-type-epidemic-weibo" class="headerlink" title="1.1链接： http://challenge.xfyun.cn/topic/info?type=epidemic-weibo"></a>1.1链接： <a href="http://challenge.xfyun.cn/topic/info?type=epidemic-weibo">http://challenge.xfyun.cn/topic/info?type=epidemic-weibo</a></h3><h3 id="1-2-赛事任务如图："><a href="#1-2-赛事任务如图：" class="headerlink" title="1.2 赛事任务如图："></a>1.2 赛事任务如图：</h3><p><img src="img.png" alt="img.png"></p><h3 id="1-3-评估指标为AUC"><a href="#1-3-评估指标为AUC" class="headerlink" title="1.3 评估指标为AUC"></a>1.3 评估指标为AUC</h3><h2 id="2-bert相关工具类"><a href="#2-bert相关工具类" class="headerlink" title="2.bert相关工具类"></a>2.bert相关工具类</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertModel<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RoleDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, texts, labels, tokenizer, max_len</span>):<br>        self.texts = texts<br>        self.labels = labels<br>        self.tokenizer = tokenizer  <span class="hljs-comment"># 分词</span><br>        self.max_len = max_len<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.texts)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, item</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        item 为数据索引，迭代取第item条数据</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        text = <span class="hljs-built_in">str</span>(self.texts[item])<br>        label = self.labels[item]<br><br>        encoding = self.tokenizer.encode_plus(<br>            text,<br>            add_special_tokens=<span class="hljs-literal">True</span>,<br>            max_length=self.max_len,<br>            return_token_type_ids=<span class="hljs-literal">True</span>,<br>            pad_to_max_length=<span class="hljs-literal">True</span>,<br>            return_attention_mask=<span class="hljs-literal">True</span>,<br>            return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>,<br>            truncation=<span class="hljs-literal">True</span><br>        )<br><br>        sampler = &#123;<br>            <span class="hljs-string">&#x27;texts&#x27;</span>: text,<br>            <span class="hljs-string">&#x27;input_ids&#x27;</span>: encoding[<span class="hljs-string">&#x27;input_ids&#x27;</span>].flatten(),<br>            <span class="hljs-string">&#x27;attention_mask&#x27;</span>: encoding[<span class="hljs-string">&#x27;attention_mask&#x27;</span>].flatten(),<br>            <span class="hljs-string">&#x27;label&#x27;</span>: torch.tensor(label)<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> sampler<br><br><br><span class="hljs-comment"># 创建数据集函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_data_loader</span>(<span class="hljs-params">df, tokenizer, max_len, batch_size</span>):<br>    ds = RoleDataset(<br>        texts=df[<span class="hljs-string">&#x27;text&#x27;</span>].values,<br>        labels=df[<span class="hljs-string">&#x27;label&#x27;</span>].values,<br>        tokenizer=tokenizer,<br>        max_len=max_len<br>    )<br><br>    <span class="hljs-keyword">return</span> DataLoader(<br>        ds,<br>        batch_size=batch_size,<br>    )<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">AttentionHead</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_features, hidden_dim</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.W = nn.Linear(in_features, hidden_dim)<br>        self.V = nn.Linear(hidden_dim, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, features</span>):<br>        att = torch.tanh(self.W(features))<br>        score = self.V(att)<br>        attention_weights = torch.softmax(score, dim=<span class="hljs-number">1</span>)<br>        context_vector = torch.<span class="hljs-built_in">sum</span>(attention_weights * features, dim=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> context_vector<br><br><br><span class="hljs-comment"># fine-tuning</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">EmotionClassifier</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_classes, PRE_TRAINED_MODEL_NAME</span>):<br>        <span class="hljs-built_in">super</span>(EmotionClassifier, self).__init__()<br>        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)<br>        self.out = nn.Linear(self.bert.config.hidden_size * <span class="hljs-number">2</span>, n_classes)<br>        self.head = AttentionHead(self.bert.config.hidden_size, self.bert.config.hidden_size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_ids, attention_mask</span>):<br>        output = self.bert(<br>            input_ids=input_ids,<br>            attention_mask=attention_mask<br>        )<br>        last_hidden_state = output[<span class="hljs-number">0</span>]<br>        input_mask_expanded = attention_mask.unsqueeze(-<span class="hljs-number">1</span>).expand(last_hidden_state.size()).<span class="hljs-built_in">float</span>()<br>        sum_embeddings = torch.<span class="hljs-built_in">sum</span>(last_hidden_state * input_mask_expanded, <span class="hljs-number">1</span>)<br>        sum_mask = input_mask_expanded.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>)<br>        sum_mask = torch.clamp(sum_mask, <span class="hljs-built_in">min</span>=<span class="hljs-number">1e-9</span>)<br>        mean_embeddings = sum_embeddings / sum_mask<br>        head_out = self.head(output[<span class="hljs-number">0</span>])<br>        all_out = torch.cat([head_out, mean_embeddings], <span class="hljs-number">1</span>)<br>        logits = self.out(all_out)<br>        <span class="hljs-keyword">return</span> logits<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FGM</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model</span>):<br>        self.model = model<br>        self.backup = &#123;&#125;<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">attack</span>(<span class="hljs-params">self, epsilon=<span class="hljs-number">1.</span>, emb_name=<span class="hljs-string">&#x27;word_embeddings&#x27;</span></span>):<br>        <span class="hljs-comment"># emb_name这个参数要换成你模型中embedding的参数名</span><br>        <span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> self.model.named_parameters():<br>            <span class="hljs-keyword">if</span> param.requires_grad <span class="hljs-keyword">and</span> emb_name <span class="hljs-keyword">in</span> name:<br>                self.backup[name] = param.data.clone()<br>                <span class="hljs-comment">#                 print(&#x27;grad: &#x27;, param.grad)</span><br>                norm = torch.norm(param.grad)<br>                <span class="hljs-keyword">if</span> norm != <span class="hljs-number">0</span>:<br>                    r_at = epsilon * param.grad / norm<br>                    param.data.add_(r_at)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">restore</span>(<span class="hljs-params">self, emb_name=<span class="hljs-string">&#x27;word_embeddings&#x27;</span></span>):<br>        <span class="hljs-comment"># emb_name这个参数要换成你模型中embedding的参数名</span><br>        <span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> self.model.named_parameters():<br>            <span class="hljs-keyword">if</span> param.requires_grad <span class="hljs-keyword">and</span> emb_name <span class="hljs-keyword">in</span> name:<br>                <span class="hljs-keyword">assert</span> name <span class="hljs-keyword">in</span> self.backup<br>                param.data = self.backup[name]<br>        self.backup = &#123;&#125;<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FocalLoss</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;Multi-class Focal loss implementation&quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, gamma=<span class="hljs-number">2</span>, weight=<span class="hljs-literal">None</span>, reduction=<span class="hljs-string">&#x27;mean&#x27;</span>, ignore_index=-<span class="hljs-number">100</span></span>):<br>        <span class="hljs-built_in">super</span>(FocalLoss, self).__init__()<br>        self.gamma = gamma<br>        self.weight = weight<br>        self.ignore_index = ignore_index<br>        self.reduction = reduction<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, inputs, target</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        input: [N, C]</span><br><span class="hljs-string">        target: [N, ]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        target = target.long()<br>        log_pt = torch.log_softmax(inputs, dim=<span class="hljs-number">1</span>)<br>        pt = torch.exp(log_pt)<br>        log_pt = (<span class="hljs-number">1</span> - pt) ** self.gamma * log_pt<br>        loss = torch.nn.functional.nll_loss(log_pt, target, self.weight, reduction=self.reduction,<br>                                            ignore_index=self.ignore_index)<br>        <span class="hljs-keyword">return</span> loss<br></code></pre></td></tr></table></figure><h2 id="3-比赛baseline"><a href="#3-比赛baseline" class="headerlink" title="3. 比赛baseline"></a>3. 比赛baseline</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import pandas as pd<br>import torch<br><span class="hljs-keyword">from</span> tools import create_data_loader, EmotionClassifier, FocalLoss, FGM<br>import torch.nn as nn<br>import warnings<br>import glob<br>import numpy as np<br><span class="hljs-keyword">from</span> transformers import BertTokenizer, AdamW, get_linear_schedule_with_warmup<br>import os<br><span class="hljs-keyword">from</span> sklearn.model_selection import StratifiedKFold<br><span class="hljs-keyword">from</span> tqdm import tqdm<br><br>os.environ[<span class="hljs-string">&#x27;CUDA_LAUNCH_BLOCKING&#x27;</span>] = <span class="hljs-string">&#x27;1&#x27;</span><br>warnings.filterwarnings(<span class="hljs-string">&#x27;ignore&#x27;</span>)<br><br>df = pd.read_csv(<span class="hljs-string">&#x27;../data/clean_data.csv&#x27;</span>)<br>train = df[0:60000]<br>train[<span class="hljs-string">&#x27;label&#x27;</span>] = train[<span class="hljs-string">&#x27;label&#x27;</span>].astype(<span class="hljs-string">&#x27;long&#x27;</span>)<br>test = df[-10000:]<br><br>RANDOM_SEED = 42<br>np.random.seed(RANDOM_SEED)<br><span class="hljs-comment"># torch.manual_seed(RANDOM_SEED)</span><br><br>device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br><span class="hljs-comment"># device = torch.device(&#x27;cpu&#x27;)</span><br><span class="hljs-built_in">print</span>(torch.cuda.is_available())<br><br>PRE_TRAINED_MODEL_NAME = <span class="hljs-string">&#x27;../pre_train_model/roberta&#x27;</span><br>tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)<br><br>skf = StratifiedKFold(<span class="hljs-attribute">n_splits</span>=5, <span class="hljs-attribute">random_state</span>=2022, <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">True</span>)<br>fold_idx = 1<br><br>EPOCHS = 1  # 训练轮数<br>BATCH_SIZE = 1<br>MAX_LEN = 20<br>LR = 3e-5<br><br><span class="hljs-keyword">for</span> train_idx, val_idx <span class="hljs-keyword">in</span> skf.split(train[<span class="hljs-string">&#x27;label&#x27;</span>], train[<span class="hljs-string">&#x27;label&#x27;</span>]):<br>    train_data_loader = create_data_loader(train.iloc[train_idx], tokenizer, MAX_LEN, BATCH_SIZE)<br>    val_data_loader = create_data_loader(train.iloc[val_idx], tokenizer, MAX_LEN, BATCH_SIZE)<br>    model = EmotionClassifier(2, PRE_TRAINED_MODEL_NAME)<br>    model.<span class="hljs-keyword">to</span>(device)<br><br>    optimizer = AdamW(model.parameters(), <span class="hljs-attribute">lr</span>=LR, <span class="hljs-attribute">weight_decay</span>=0.01)<br>    total_steps = len(train_data_loader) * EPOCHS<br><br>   <span class="hljs-built_in"> scheduler </span>= get_linear_schedule_with_warmup(<br>        optimizer,<br>        <span class="hljs-attribute">num_warmup_steps</span>=0.1,<br>        <span class="hljs-attribute">num_training_steps</span>=total_steps<br>    )<br><br>    loss_fn = FocalLoss().<span class="hljs-keyword">to</span>(device)<br><br>    best_acc = 0<br>    fgm = FGM(model)<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(EPOCHS):<br>        # 训练<br>        model = model.train()<br>        j = 1<br>        <span class="hljs-keyword">for</span> sample <span class="hljs-keyword">in</span> tqdm(train_data_loader):<br>            input_ids = sample[<span class="hljs-string">&quot;input_ids&quot;</span>].<span class="hljs-keyword">to</span>(device)<br>            attention_mask = sample[<span class="hljs-string">&quot;attention_mask&quot;</span>].<span class="hljs-keyword">to</span>(device)<br>            label = sample[<span class="hljs-string">&#x27;label&#x27;</span>].<span class="hljs-keyword">to</span>(device)<br>            logits = model(<br>                <span class="hljs-attribute">input_ids</span>=input_ids,<br>                <span class="hljs-attribute">attention_mask</span>=attention_mask<br>            )<br>            loss = loss_fn(logits, label)<br><br>            <span class="hljs-keyword">if</span> j % 50 == 0:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Train %d: loss:%f&#x27;</span> % (j, loss.detach().cpu().numpy()))<br>            loss.backward()<br>            nn.utils.clip_grad_norm_(model.parameters(), <span class="hljs-attribute">max_norm</span>=1.0)<br>            # 对抗训练<br>            fgm.attack()  # 在embedding上添加对抗扰动<br>            loss_adv = model(<br>                <span class="hljs-attribute">input_ids</span>=input_ids,<br>                <span class="hljs-attribute">attention_mask</span>=attention_mask<br>            )<br>            loss_adv2 = loss_fn(loss_adv, label)<br>            loss_adv2.backward()  # 反向传播，并在正常的grad基础上，累加对抗训练的梯度<br>            fgm.restore()  # 恢复embedding参数<br><br>            optimizer.<span class="hljs-keyword">step</span>()<br>            scheduler.<span class="hljs-keyword">step</span>()<br>            optimizer.zero_grad()<br><br>            # 验证<br>            <span class="hljs-keyword">if</span> (j % 100 == 0) <span class="hljs-keyword">or</span> (j % len(train_data_loader) == 0):<br>                all_pred, all_label = [], []<br>                with torch.no_grad():<br>                    model = model.eval()<br>                    <span class="hljs-keyword">for</span> sampler <span class="hljs-keyword">in</span> val_data_loader:<br>                        input_ids = sampler[<span class="hljs-string">&quot;input_ids&quot;</span>].<span class="hljs-keyword">to</span>(device)<br>                        attention_mask = sampler[<span class="hljs-string">&quot;attention_mask&quot;</span>].<span class="hljs-keyword">to</span>(device)<br>                        label = sampler[<span class="hljs-string">&#x27;label&#x27;</span>].<span class="hljs-keyword">to</span>(device)<br>                        logits = model(<br>                            <span class="hljs-attribute">input_ids</span>=input_ids,<br>                            <span class="hljs-attribute">attention_mask</span>=attention_mask<br>                        )<br>                        all_pred.extend(logits.argmax(-1).detach().cpu().numpy())<br>                        all_label.extend(label.detach().cpu().numpy())<br>                    model = model.train()<br>                    acc = (np.array(all_label) == np.array(all_pred)).astype(np.float32).mean()<br>                    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Val acc %.5f&#x27;</span> % acc)<br>                    <span class="hljs-keyword">if</span> acc &gt; best_acc:<br>                        best_acc = acc<br>                        torch.save(model.state_dict(), <span class="hljs-string">&#x27;../models//&#x27;</span> + str(fold_idx) + <span class="hljs-string">&#x27;.pth&#x27;</span>)<br>            j += 1<br>    fold_idx += 1<br>    <br><span class="hljs-comment"># 预测</span><br>test[<span class="hljs-string">&#x27;label&#x27;</span>] = 0<br>test_data_loader = create_data_loader(test, tokenizer, MAX_LEN, BATCH_SIZE)<br><br>test_pred_tta = None<br><span class="hljs-keyword">for</span> path <span class="hljs-keyword">in</span> glob.glob(<span class="hljs-string">&#x27;../models//*.pth&#x27;</span>):<br>    # 加载模型<br>    <span class="hljs-built_in">print</span>(path)<br>    model = EmotionClassifier(2, PRE_TRAINED_MODEL_NAME)<br>    model.load_state_dict(torch.load(path, <span class="hljs-attribute">map_location</span>=<span class="hljs-string">&quot;cpu&quot;</span>))<br>    model.<span class="hljs-keyword">to</span>(device)<br><br>    test_pred = []<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;load model finished&quot;</span>)<br>    with torch.no_grad():<br>        model.eval()<br>        <span class="hljs-keyword">for</span> sample <span class="hljs-keyword">in</span> test_data_loader:<br>            input_ids = sample[<span class="hljs-string">&quot;input_ids&quot;</span>].<span class="hljs-keyword">to</span>(device)<br>            attention_mask = sample[<span class="hljs-string">&quot;attention_mask&quot;</span>].<span class="hljs-keyword">to</span>(device)<br>            logits = model(<br>                <span class="hljs-attribute">input_ids</span>=input_ids,<br>                <span class="hljs-attribute">attention_mask</span>=attention_mask<br>            )<br>            test_pred.append(logits.detach().cpu().numpy())<br><br>    <span class="hljs-keyword">if</span> test_pred_tta is None:<br>        test_pred_tta = np.vstack(test_pred)<br>    <span class="hljs-keyword">else</span>:<br>        test_pred_tta += np.vstack(test_pred)<br><br><span class="hljs-comment"># 生成结果</span><br>test[<span class="hljs-string">&#x27;label&#x27;</span>] = test_pred_tta.argmax(1)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
